{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to replace the `VolatileMemoryStore` memory storage used in a [previous notebook](./06-memory-and-embeddings.ipynb) with a `WeaviateMemoryStore`.\n",
    "\n",
    "`WeaviateMemoryStore` is an example of a persistent (i.e. long-term) memory store backed by the Weaviate vector database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Weaviate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Weaviate](https://weaviate.io/) is an open-source vector database designed to scale seamlessly into billions of data objects. This implementation supports hybrid search out-of-the-box (meaning it will perform better for keyword searches)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run Weaviate in 5 ways:\n",
    "\n",
    "- **SaaS** – with [Weaviate Cloud Services (WCS)](https://weaviate.io/pricing).\n",
    "\n",
    "  WCS is a fully managed service that takes care of hosting, scaling, and updating your Weaviate instance. You can try it out for free with a sandbox that lasts for 14 days.\n",
    "\n",
    "  To set up a SaaS Weaviate instance with WCS:\n",
    "\n",
    "  1.  Navigate to [Weaviate Cloud Console](https://console.weaviate.cloud/).\n",
    "  2.  Register or sign in to your WCS account.\n",
    "  3.  Create a new cluster with the following settings:\n",
    "      - `Subscription Tier` – Free sandbox for a free trial, or contact [hello@weaviate.io](mailto:hello@weaviate.io) for other options.\n",
    "      - `Cluster name` – a unique name for your cluster. The name will become part of the URL used to access this instance.\n",
    "      - `Enable Authentication?` – Enabled by default. This will generate a static API key that you can use to authenticate.\n",
    "  4.  Wait for a few minutes until your cluster is ready. You will see a green tick ✔️ when it's done. Copy your cluster URL.\n",
    "\n",
    "- **Hybrid SaaS**\n",
    "\n",
    "  > If you need to keep your data on-premise for security or compliance reasons, Weaviate also offers a Hybrid SaaS option: Weaviate runs within your cloud instances, but the cluster is managed remotely by Weaviate. This gives you the benefits of a managed service without sending data to an external party.\n",
    "\n",
    "  The Weaviate Hybrid SaaS is a custom solution. If you are interested in this option, please reach out to [hello@weaviate.io](mailto:hello@weaviate.io).\n",
    "\n",
    "- **Self-hosted** – with a Docker container\n",
    "\n",
    "  To set up a Weaviate instance with Docker:\n",
    "\n",
    "  1. [Install Docker](https://docs.docker.com/engine/install/) on your local machine if it is not already installed.\n",
    "  2. [Install the Docker Compose Plugin](https://docs.docker.com/compose/install/)\n",
    "  3. Download a `docker-compose.yml` file with this `curl` command:\n",
    "\n",
    "     ```\n",
    "     curl -o docker-compose.yml \"https://configuration.weaviate.io/v2/docker-compose/docker-compose.yml?modules=standalone&runtime=docker-compose&weaviate_version=v1.19.6\"\n",
    "     ```\n",
    "\n",
    "     Alternatively, you can use Weaviate's docker compose [configuration tool](https://weaviate.io/developers/weaviate/installation/docker-compose) to generate your own `docker-compose.yml` file.\n",
    "\n",
    "  4. Run `docker compose up -d` to spin up a Weaviate instance.\n",
    "\n",
    "     > To shut it down, run `docker compose down`.\n",
    "\n",
    "- **Self-hosted** – with a Kubernetes cluster\n",
    "\n",
    "  To configure a self-hosted instance with Kubernetes, follow Weaviate's [documentation](https://weaviate.io/developers/weaviate/installation/kubernetes).|\n",
    "\n",
    "- **Embedded** - start a weaviate instance right from your application code using the client library\n",
    "   \n",
    "  This code snippet shows how to instantiate an embedded weaviate instance and upload a document:\n",
    "\n",
    "  ```python\n",
    "  import weaviate\n",
    "  from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "  client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions()\n",
    "  )\n",
    "\n",
    "  data_obj = {\n",
    "    \"name\": \"Chardonnay\",\n",
    "    \"description\": \"Goes with fish\"\n",
    "  }\n",
    "\n",
    "  client.data_object.create(data_obj, \"Wine\")\n",
    "  ```\n",
    "  \n",
    "  Refer to the [documentation](https://weaviate.io/developers/weaviate/installation/embedded) for more details about this deployment method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semantic-kernel==0.3.0.dev0\n",
      "  Downloading semantic_kernel-0.3.0.dev0-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.3/94.3 kB\u001b[0m \u001b[31m869.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m797.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from semantic-kernel==0.3.0.dev0) (23.1.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from semantic-kernel==0.3.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: openai<0.28.0,>=0.27.0 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from semantic-kernel==0.3.0.dev0) (0.27.7)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.0.dev0) (1.3.1)\n",
      "Installing collected packages: semantic-kernel\n",
      "  Attempting uninstall: semantic-kernel\n",
      "    Found existing installation: semantic-kernel 0.2.9.dev0\n",
      "    Uninstalling semantic-kernel-0.2.9.dev0:\n",
      "      Successfully uninstalled semantic-kernel-0.2.9.dev0\n",
      "Successfully installed semantic-kernel-0.3.0.dev0\n",
      "Requirement already satisfied: weaviate-client in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (3.19.2)\n",
      "Requirement already satisfied: requests<2.29.0,>=2.28.0 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from weaviate-client) (2.28.2)\n",
      "Requirement already satisfied: validators<=0.21.0,>=0.18.2 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from weaviate-client) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.59.0 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from weaviate-client) (4.65.0)\n",
      "Requirement already satisfied: authlib>=1.1.0 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from weaviate-client) (1.2.0)\n",
      "Requirement already satisfied: cryptography>=3.2 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from authlib>=1.1.0->weaviate-client) (41.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from requests<2.29.0,>=2.28.0->weaviate-client) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from requests<2.29.0,>=2.28.0->weaviate-client) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from requests<2.29.0,>=2.28.0->weaviate-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from requests<2.29.0,>=2.28.0->weaviate-client) (2023.5.7)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from validators<=0.21.0,>=0.18.2->weaviate-client) (5.1.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from cryptography>=3.2->authlib>=1.1.0->weaviate-client) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.2->authlib>=1.1.0->weaviate-client) (2.21)\n",
      "Requirement already satisfied: python-dotenv in /Users/dandv/Library/Caches/pypoetry/virtualenvs/semantic-kernel-tJOEiq7p-py3.11/lib/python3.11/site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install semantic-kernel==0.3.0.dev0\n",
    "!pip install weaviate-client\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OS-specific notes:\n",
    "* if you run into SSL errors when connecting to OpenAI on macOS, see this issue for a [potential solution](https://github.com/microsoft/semantic-kernel/issues/627#issuecomment-1580912248)\n",
    "* on Windows, you may need to run Docker Desktop as administrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    OpenAITextCompletion,\n",
    "    OpenAITextEmbedding,\n",
    ")\n",
    "\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we instantiate the Weaviate memory store. Uncomment ONE of the options below, depending on how you want to use Weaviate:\n",
    "* from a Docker instance\n",
    "* from WCS\n",
    "* directly from the client (embedded Weaviate), which works on Linux only at the  moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.memory import weaviate_memory_store\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Using Docker\n",
    "config = weaviate_memory_store.WeaviateConfig(url=\"http://localhost:8080\")\n",
    "\n",
    "# Using WCS. Make sure the environment variables `WEAVIATE_URL` and `WEAVIATE_API_KEY` were set in the `.env` file.\n",
    "#config = weaviate_memory_store.WeaviateConfig(\n",
    "#    url=os.getenv(\"WEAVIATE_URL\"),\n",
    "#    api_key=os.getenv(\"WEAVIATE_API_KEY\")\n",
    "#)\n",
    "\n",
    "# Using Embedded Weaviate\n",
    "#config = weaviate_memory_store.WeaviateConfig(use_embed=True)\n",
    "\n",
    "store = weaviate_memory_store.WeaviateMemoryStore(config=config)\n",
    "store.client.schema.delete_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we register the memory store to the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': <semantic_kernel.orchestration.sk_function.SKFunction at 0x103c21250>,\n",
       " 'save': <semantic_kernel.orchestration.sk_function.SKFunction at 0x105926710>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "\n",
    "api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "kernel.add_text_completion_service(\n",
    "    \"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id)\n",
    ")\n",
    "kernel.add_text_embedding_generation_service(\n",
    "    \"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id)\n",
    ")\n",
    "\n",
    "kernel.register_memory_store(memory_store=store)\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually adding memories\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some initial memories \"About Me\". We can add memories to our weaviate memory store by using `save_information_async`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION = \"AboutMe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def populate_memory(kernel: sk.Kernel) -> None:\n",
    "    # Add some documents to the semantic memory\n",
    "    await kernel.memory.save_information_async(\n",
    "        COLLECTION, id=\"info1\", text=\"My name is Andrea\"\n",
    "    )\n",
    "    await kernel.memory.save_information_async(\n",
    "        COLLECTION, id=\"info2\", text=\"I currently work as a tour guide\"\n",
    "    )\n",
    "    await kernel.memory.save_information_async(\n",
    "        COLLECTION, id=\"info3\", text=\"I've been living in Seattle since 2005\"\n",
    "    )\n",
    "    await kernel.memory.save_information_async(\n",
    "        COLLECTION, id=\"info4\", text=\"I visited France and Italy five times since 2015\"\n",
    "    )\n",
    "    await kernel.memory.save_information_async(\n",
    "        COLLECTION, id=\"info5\", text=\"My family is from New York\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching is done through `search_async`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_memory_examples(kernel: sk.Kernel) -> None:\n",
    "    questions = [\n",
    "        \"what's my name\",\n",
    "        \"where do I live?\",\n",
    "        \"where's my family from?\",\n",
    "        \"where have I traveled?\",\n",
    "        \"what do I do for work\",\n",
    "    ]\n",
    "\n",
    "    for question in questions:\n",
    "        print(f\"Question: {question}\")\n",
    "        result = await kernel.memory.search_async(COLLECTION, question)\n",
    "        print(f\"Answer: {result[0].text}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results of the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating memory...\n",
      "Asking questions... (manually)\n",
      "Question: what's my name\n",
      "Answer: My name is Andrea\n",
      "\n",
      "Question: where do I live?\n",
      "Answer: I've been living in Seattle since 2005\n",
      "\n",
      "Question: where's my family from?\n",
      "Answer: My family is from New York\n",
      "\n",
      "Question: where have I traveled?\n",
      "Answer: I visited France and Italy five times since 2015\n",
      "\n",
      "Question: what do I do for work\n",
      "Answer: I currently work as a tour guide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Populating memory...\")\n",
    "await populate_memory(kernel)\n",
    "\n",
    "print(\"Asking questions... (manually)\")\n",
    "await search_memory_examples(kernel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to use the weaviate memory store in a chat application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_chat_with_memory(\n",
    "    kernel: sk.Kernel,\n",
    ") -> Tuple[sk.SKFunctionBase, sk.SKContext]:\n",
    "    sk_prompt = \"\"\"\n",
    "    ChatBot can have a conversation with you about any topic.\n",
    "    It can give explicit instructions or say 'I don't know' if\n",
    "    it does not have an answer.\n",
    "\n",
    "    Information about me, from previous conversations:\n",
    "    - {{$fact1}} {{recall $fact1}}\n",
    "    - {{$fact2}} {{recall $fact2}}\n",
    "    - {{$fact3}} {{recall $fact3}}\n",
    "    - {{$fact4}} {{recall $fact4}}\n",
    "    - {{$fact5}} {{recall $fact5}}\n",
    "\n",
    "    Chat:\n",
    "    {{$chat_history}}\n",
    "    User: {{$user_input}}\n",
    "    ChatBot: \"\"\".strip()\n",
    "\n",
    "    chat_func = kernel.create_semantic_function(\n",
    "        sk_prompt, max_tokens=200, temperature=0.8\n",
    "    )\n",
    "\n",
    "    context = kernel.create_new_context()\n",
    "    context[\"fact1\"] = \"what is my name?\"\n",
    "    context[\"fact2\"] = \"where do I live?\"\n",
    "    context[\"fact3\"] = \"where's my family from?\"\n",
    "    context[\"fact4\"] = \"where have I traveled?\"\n",
    "    context[\"fact5\"] = \"what do I do for work?\"\n",
    "\n",
    "    context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = COLLECTION\n",
    "    context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
    "\n",
    "    context[\"chat_history\"] = \"\"\n",
    "\n",
    "    return chat_func, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(\n",
    "    kernel: sk.Kernel, chat_func: sk.SKFunctionBase, context: sk.SKContext\n",
    ") -> bool:\n",
    "    try:\n",
    "        user_input = input(\"User:> \")\n",
    "        context[\"user_input\"] = user_input\n",
    "        print(f\"User:> {user_input}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "    except EOFError:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "\n",
    "    answer = await kernel.run_async(chat_func, input_vars=context.variables)\n",
    "    context[\"chat_history\"] += f\"\\nUser:> {user_input}\\nChatBot:> {answer}\\n\"\n",
    "\n",
    "    print(f\"ChatBot:> {answer}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up a chat (with memory!)\n",
      "Begin chatting (type 'exit' to exit):\n",
      "\n",
      "User:> hi\n",
      "ChatBot:>  Hi there! How can I help you?\n",
      "User:> where is my family from?\n",
      "ChatBot:>  Your family is from New York.\n",
      "User:> tell me a joke\n",
      "ChatBot:>  Why did the chicken cross the playground?\n",
      "    To get to the other slide!\n",
      "User:> bye!\n",
      "ChatBot:> Error: (<ErrorCodes.ServiceError: 6>, 'OpenAI service failed to complete the prompt', RateLimitError(message='The server had an error while processing your request. Sorry about that!', http_status=429, request_id=None))\n",
      "User:> exit\n",
      "\n",
      "\n",
      "Exiting chat...\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up a chat (with memory!)\")\n",
    "chat_func, context = await setup_chat_with_memory(kernel)\n",
    "\n",
    "print(\"Begin chatting (type 'exit' to exit):\\n\")\n",
    "chatting = True\n",
    "while chatting:\n",
    "    chatting = await chat(kernel, chat_func, context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding documents to your memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to hold some files. The key is the hyperlink to the file and the value is the file's content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_files = {}\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/blob/main/README.md\"\n",
    "] = \"README: Installation, getting started, and how to contribute\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/blob/main/dotnet/notebooks/02-running-prompts-from-file.ipynb\"\n",
    "] = \"Jupyter notebook describing how to pass prompts from a file to a semantic skill or function\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/blob/main/dotnet/notebooks/00-getting-started.ipynb\"\n",
    "] = \"Jupyter notebook describing how to get started with the Semantic Kernel\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/tree/main/prompts/samples/ChatPlugin/ChatGPT\"\n",
    "] = \"Sample demonstrating how to create a chat skill interfacing with ChatGPT\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/blob/main/dotnet/src/SemanticKernel/Memory/Volatile/VolatileMemoryStore.cs\"\n",
    "] = \"C# class that defines a volatile embedding store\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/tree/main/samples/dotnet/KernelHttpServer/README.md\"\n",
    "] = \"README: How to set up a Semantic Kernel Service API using Azure Function Runtime v4\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/tree/main/samples/apps/chat-summary-webapp-react/README.md\"\n",
    "] = \"README: README associated with a sample starter react-based chat summary webapp\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `save_reference_async` to save the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding some GitHub file URLs and their descriptions to a volatile Semantic Memory.\n",
      "  URL 1 saved\n",
      "  URL 2 saved\n",
      "  URL 3 saved\n",
      "  URL 4 saved\n",
      "  URL 5 saved\n",
      "  URL 6 saved\n",
      "  URL 7 saved\n"
     ]
    }
   ],
   "source": [
    "COLLECTION = \"SKGitHub\"\n",
    "\n",
    "print(\n",
    "    \"Adding some GitHub file URLs and their descriptions to a volatile Semantic Memory.\"\n",
    ")\n",
    "i = 0\n",
    "for entry, value in github_files.items():\n",
    "    await kernel.memory.save_reference_async(\n",
    "        collection=COLLECTION,\n",
    "        description=value,\n",
    "        text=value,\n",
    "        external_id=entry,\n",
    "        external_source_name=\"GitHub\",\n",
    "    )\n",
    "    i += 1\n",
    "    print(\"  URL {} saved\".format(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `search_async` to ask a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Query: I love Jupyter notebooks, how should I get started?\n",
      "\n",
      "Result 1:\n",
      "  URL:     : https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/dotnet/00-getting-started.ipynb\n",
      "  Title    : Jupyter notebook describing how to get started with the Semantic Kernel\n",
      "  Relevance: 0.9338777661323547\n",
      "\n",
      "Result 2:\n",
      "  URL:     : https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/dotnet/02-running-prompts-from-file.ipynb\n",
      "  Title    : Jupyter notebook describing how to pass prompts from a file to a semantic skill or function\n",
      "  Relevance: 0.9082032442092896\n",
      "\n",
      "Result 3:\n",
      "  URL:     : https://github.com/microsoft/semantic-kernel/blob/main/README.md\n",
      "  Title    : README: Installation, getting started, and how to contribute\n",
      "  Relevance: 0.9042205810546875\n",
      "\n",
      "Result 4:\n",
      "  URL:     : https://github.com/microsoft/semantic-kernel/tree/main/samples/apps/chat-summary-webapp-react/README.md\n",
      "  Title    : README: README associated with a sample starter react-based chat summary webapp\n",
      "  Relevance: 0.8821048438549042\n",
      "\n",
      "Result 5:\n",
      "  URL:     : https://github.com/microsoft/semantic-kernel/tree/main/samples/skills/ChatSkill/ChatGPT\n",
      "  Title    : Sample demonstrating how to create a chat skill interfacing with ChatGPT\n",
      "  Relevance: 0.8685075342655182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask = \"I love Jupyter notebooks, how should I get started?\"\n",
    "print(\"===========================\\n\" + \"Query: \" + ask + \"\\n\")\n",
    "\n",
    "memories = await kernel.memory.search_async(\n",
    "    COLLECTION, ask, limit=5, min_relevance_score=0.77\n",
    ")\n",
    "\n",
    "i = 0\n",
    "for memory in memories:\n",
    "    i += 1\n",
    "    print(f\"Result {i}:\")\n",
    "    print(\"  URL:     : \" + memory.id)\n",
    "    print(\"  Title    : \" + memory.description)\n",
    "    print(\"  Relevance: \" + str(memory.relevance))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
