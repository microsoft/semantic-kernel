# Copyright (c) Microsoft. All rights reserved.

import logging
from collections.abc import Sequence
from inspect import Parameter, _empty, signature
from types import MappingProxyType, NoneType
from typing import Annotated, Any, Protocol, TypeVar, runtime_checkable
from warnings import warn

from pydantic import ConfigDict, Field, model_validator
from pydantic.dataclasses import dataclass

from semantic_kernel.connectors.ai.embedding_generator_base import EmbeddingGeneratorBase
from semantic_kernel.data.const import DistanceFunction, IndexKind
from semantic_kernel.exceptions import VectorStoreModelException
from semantic_kernel.kernel_pydantic import KernelBaseModel
from semantic_kernel.utils.feature_stage_decorator import release_candidate

logger = logging.getLogger(__name__)


# region: Fields


@release_candidate
@dataclass(kw_only=True, config=ConfigDict(extra="allow"))
class VectorStoreRecordField:
    """Vector store record fields.

    Args:
        name: The name of the field.
        property_type: The type of the field.
        storage_property_name: The name of the field in the store, uses the field name by default.

    """

    name: str = Field(default="")
    property_type: str | None = None
    storage_property_name: str | None = None

    @model_validator(mode="before")
    @classmethod
    def check_deprecated_fields(cls, data: dict[str, Any]) -> dict[str, Any]:
        """Check for deprecated fields.

        Args:
            data: The data to check.

        Returns:
            The data with the deprecated fields removed.
        """
        if isinstance(data, dict):
            if "is_filterable" in data:
                warn(
                    "The is_filterable field is deprecated. Please use the is_indexed field instead.",
                    DeprecationWarning,
                )
                data["is_indexed"] = data.pop("is_filterable")
            if "is_full_text_searchable" in data:
                warn(
                    "The is_full_text_searchable field is deprecated. "
                    "Please use the is_full_text_indexed field instead.",
                    DeprecationWarning,
                )
                data["is_full_text_indexed"] = data.pop("is_full_text_searchable")
            if "local_embedding" in data:
                warn(
                    "The local_embedding field is deprecated. "
                    "Please use the has_embedding and has_local_embedding field on the data field instead.",
                    DeprecationWarning,
                )
                data.pop("local_embedding")
        return data


@release_candidate
@dataclass(kw_only=True)
class VectorStoreRecordKeyField(VectorStoreRecordField):
    """Memory record key field.

    When the key will be auto-generated by the store, make sure it has a default, usually None.

    Args:
        name: The name of the field.
        property_type: The type of the field.
    """


@release_candidate
@dataclass(kw_only=True)
class VectorStoreRecordDataField(VectorStoreRecordField):
    """Memory record data field.

    Args:
        name: The name of the field.
        property_type: The type of the field.
        is_indexed: Whether the field is indexed.
        is_full_text_indexed: Whether the field is full text indexed.
    """

    is_indexed: bool | None = None
    is_full_text_indexed: bool | None = None


@release_candidate
@dataclass(kw_only=True)
class VectorStoreRecordVectorField(VectorStoreRecordField):
    """Memory record vector field.

    This field should contain the value you want to use for the vector.
    When passing in the embedding generator, the embedding will be
    generated locally before upserting.
    If this is not set, the store should support generating the embedding for you.
    If you want to retrieve the original content of the vector,
    make sure to set this field twice,
    once with the VectorStoreRecordDataField and once with the VectorStoreRecordVectorField.

    If you want to be able to get the vectors back, make sure the type allows this, especially for pydantic models.
    For instance, if the input is a string, then the type annotation should be `str | list[float] | None`.

    If you want to cast the vector that is returned, you need to set the deserialize_function,
    for instance: `deserialize_function=np.array`, (with `import numpy as np` at the top of your file).
    If you want to set it up with more specific options, use a lambda, a custom function or a partial.

    Args:
        name: The name of the field.
        property_type: Property type.
            For vectors this should be the inner type of the vector.
            By default the vector will be a list of numbers.
            If you want to use a numpy array or some other optimized format,
            set the cast_function with a function
            that takes a list of floats and returns a numpy array.
        dimensions: The number of dimensions of the vector.
        index_kind: The index kind to use.
        distance_function: The distance function to use.
        embedding_generator: The embedding generator to use.
            If this is set, the embedding will be generated locally before upserting.
    """

    dimensions: Annotated[int, Field(gt=0)]
    index_kind: IndexKind = IndexKind.DEFAULT
    distance_function: DistanceFunction = DistanceFunction.DEFAULT
    embedding_generator: EmbeddingGeneratorBase | None = None
    embedding_property_type: str | None = None


# region: Protocols


@runtime_checkable
class ToDictFunctionProtocol(Protocol):
    """Protocol for to_dict function.

    Args:
        record: The record to be serialized.
        **kwargs: Additional keyword arguments.

    Returns:
        A list of dictionaries.
    """

    def __call__(self, record: Any, **kwargs: Any) -> Sequence[dict[str, Any]]: ...  # pragma: no cover  # noqa: D102


@runtime_checkable
class FromDictFunctionProtocol(Protocol):
    """Protocol for from_dict function.

    Args:
        records: A list of dictionaries.
        **kwargs: Additional keyword arguments.

    Returns:
        A record or list thereof.
    """

    def __call__(self, records: Sequence[dict[str, Any]], **kwargs: Any) -> Any: ...  # noqa: D102


@runtime_checkable
class SerializeFunctionProtocol(Protocol):
    """Protocol for serialize function.

    Args:
        record: The record to be serialized.
        **kwargs: Additional keyword arguments.

    Returns:
        The serialized record, ready to be consumed by the specific store.

    """

    def __call__(self, record: Any, **kwargs: Any) -> Any: ...  # noqa: D102


@runtime_checkable
class DeserializeFunctionProtocol(Protocol):
    """Protocol for deserialize function.

    Args:
        records: The serialized record directly from the store.
        **kwargs: Additional keyword arguments.

    Returns:
        The deserialized record in the format expected by the application.

    """

    def __call__(self, records: Any, **kwargs: Any) -> Any: ...  # noqa: D102


@runtime_checkable
class SerializeMethodProtocol(Protocol):
    """Data model serialization protocol.

    This can optionally be implemented to allow single step serialization and deserialization
    for using your data model with a specific datastore.
    """

    def serialize(self, **kwargs: Any) -> Any:
        """Serialize the object to the format required by the data store."""
        ...  # pragma: no cover


@runtime_checkable
class ToDictMethodProtocol(Protocol):
    """Class used internally to check if a model has a to_dict method."""

    def to_dict(self, *args: Any, **kwargs: Any) -> dict[str, Any]:
        """Serialize the object to the format required by the data store."""
        ...  # pragma: no cover


# region: VectorStoreRecordDefinition

VectorStoreRecordFields = VectorStoreRecordKeyField | VectorStoreRecordDataField | VectorStoreRecordVectorField


@release_candidate
class VectorStoreRecordDefinition(KernelBaseModel):
    """Memory record definition.

    Args:
        fields: The fields of the record.
        container_mode: Whether the record is in container mode.
        to_dict: The to_dict function, should take a record and return a list of dicts.
        from_dict: The from_dict function, should take a list of dicts and return a record.
        deserialize: The deserialize function, should take a type specific to a datastore and return a record.

    """

    fields: list[VectorStoreRecordFields]
    key_field_name: str = Field(default="", init=False)
    container_mode: bool = False
    collection_name: str | None = None
    to_dict: ToDictFunctionProtocol | None = None
    from_dict: FromDictFunctionProtocol | None = None
    serialize: SerializeFunctionProtocol | None = None
    deserialize: DeserializeFunctionProtocol | None = None

    @property
    def field_names(self) -> list[str]:
        """Get the names of the fields."""
        return [field.name for field in self.fields]

    @property
    def storage_property_names(self) -> list[str]:
        """Get the names of the fields for storage."""
        return [field.storage_property_name or field.name for field in self.fields]

    @property
    def key_field(self) -> "VectorStoreRecordKeyField":
        """Get the key field."""
        return next((field for field in self.fields if field.name == self.key_field_name), None)  # type: ignore

    @property
    def key_field_storage_property_name(self) -> str:
        """Get the key field storage property name."""
        return self.key_field.storage_property_name or self.key_field.name

    @property
    def vector_fields(self) -> list["VectorStoreRecordVectorField"]:
        """Get the names of the vector fields."""
        return [field for field in self.fields if isinstance(field, VectorStoreRecordVectorField)]

    @property
    def data_fields(self) -> list["VectorStoreRecordDataField"]:
        """Get the names of the vector fields."""
        return [field for field in self.fields if isinstance(field, VectorStoreRecordDataField)]

    @property
    def vector_field_names(self) -> list[str]:
        """Get the names of the vector fields."""
        return [field.name for field in self.fields if isinstance(field, VectorStoreRecordVectorField)]

    @property
    def data_field_names(self) -> list[str]:
        """Get the names of all the data fields."""
        return [field.name for field in self.fields if isinstance(field, VectorStoreRecordDataField)]

    def try_get_vector_field(self, field_name: str | None = None) -> VectorStoreRecordVectorField | None:
        """Try to get the vector field.

        If the field_name is None, then the first vector field is returned.
        If no vector fields are present None is returned.

        Args:
            field_name: The field name.

        Returns:
            VectorStoreRecordVectorField | None: The vector field or None.
        """
        if field_name is None:
            if len(self.vector_fields) == 0:
                return None
            return self.vector_fields[0]
        for field in self.fields:
            if field.name == field_name or field.storage_property_name == field_name:
                if isinstance(field, VectorStoreRecordVectorField):
                    return field
                raise VectorStoreModelException(
                    f"Field {field_name} is not a vector field, it is of type {type(field).__name__}."
                )
        raise VectorStoreModelException(f"Field {field_name} not found.")

    def get_storage_property_names(
        self, include_vector_fields: bool = True, include_key_field: bool = True
    ) -> list[str]:
        """Get the names of the fields for the storage.

        Args:
            include_vector_fields: Whether to include vector fields.
            include_key_field: Whether to include the key field.

        Returns:
            list[str]: The names of the fields.
        """
        return [
            field.storage_property_name or field.name
            for field in self.fields
            if (include_vector_fields or not isinstance(field, VectorStoreRecordVectorField))
            and (include_key_field or field.name != self.key_field_name)
        ]

    def get_field_names(self, include_vector_fields: bool = True, include_key_field: bool = True) -> list[str]:
        """Get the names of the fields.

        Args:
            include_vector_fields: Whether to include vector fields.
            include_key_field: Whether to include the key field.

        Returns:
            list[str]: The names of the fields.
        """
        return [
            field.name
            for field in self.fields
            if (include_vector_fields or not isinstance(field, VectorStoreRecordVectorField))
            and (include_key_field or field.name != self.key_field_name)
        ]

    def model_post_init(self, _: Any):
        """Validate the fields.

        Raises:
            VectorStoreModelException: If there is a field with an embedding property name
                but no corresponding vector field.
            VectorStoreModelException: If there is no key field.
        """
        if len(self.fields) == 0:
            raise VectorStoreModelException(
                "There must be at least one field with a VectorStoreRecordField annotation."
            )
        for field in self.fields:
            if isinstance(field, VectorStoreRecordKeyField):
                if self.key_field_name != "":
                    raise VectorStoreModelException("Memory record definition must have exactly one key field.")
                self.key_field_name = field.name
        if not self.key_field_name:
            raise VectorStoreModelException("Memory record definition must have exactly one key field.")


# region: Signature parsing functions


def _parse_vector_store_record_field_class(
    field_type: type[VectorStoreRecordField], field: Parameter
) -> VectorStoreRecordField:
    property_type = field.annotation.__origin__
    if (args := getattr(property_type, "__args__", None)) and NoneType in args and len(args) == 2:
        property_type = args[0]
    property_type_name = str(property_type) if hasattr(property_type, "__args__") else property_type.__name__
    return field_type(name=field.name, property_type=property_type_name)


def _parse_vector_store_record_field_instance(
    record_field: VectorStoreRecordField, field: Parameter
) -> VectorStoreRecordField:
    if not record_field.name or record_field.name != field.name:
        record_field.name = field.name
    if not record_field.property_type and hasattr(field.annotation, "__origin__"):
        property_type = field.annotation.__origin__
        if isinstance(record_field, VectorStoreRecordVectorField):
            if args := getattr(property_type, "__args__", None):
                if NoneType in args and len(args) > 1:
                    for arg in args:
                        if arg is NoneType:
                            continue

                        if (
                            (inner_args := getattr(arg, "__args__", None))
                            and len(inner_args) == 1
                            and inner_args[0] is not NoneType
                        ):
                            property_type = inner_args[0]
                            break
                        property_type = arg
                        break
                else:
                    property_type = args[0]

        else:
            if (args := getattr(property_type, "__args__", None)) and NoneType in args and len(args) == 2:
                property_type = args[0]

        record_field.property_type = (
            str(property_type) if hasattr(property_type, "__args__") else property_type.__name__
        )

    return record_field


def _parse_parameter_to_field(field: Parameter) -> VectorStoreRecordField | None:
    # first check if there are any annotations
    if field.annotation is not _empty and hasattr(field.annotation, "__metadata__"):
        for field_annotation in field.annotation.__metadata__:
            if isinstance(field_annotation, VectorStoreRecordField):
                return _parse_vector_store_record_field_instance(field_annotation, field)
            if isinstance(field_annotation, type(VectorStoreRecordField)):
                return _parse_vector_store_record_field_class(field_annotation, field)
    # This means there are no annotations or that all annotations are of other types.
    # we will check if there is a default, otherwise this will cause a runtime error.
    # because it will not be stored, and retrieving this object will fail without a default for this field.
    if field.default is _empty:
        raise VectorStoreModelException(
            "Fields that do not have a VectorStoreRecordField annotation must have a default value."
        )
    logger.debug(
        f'Field "{field.name}" does not have a VectorStoreRecordField annotation, will not be part of the record.'
    )
    return None


def _parse_signature_to_definition(
    parameters: MappingProxyType[str, Parameter], collection_name: str | None = None
) -> VectorStoreRecordDefinition:
    if len(parameters) == 0:
        raise VectorStoreModelException(
            "There must be at least one field in the datamodel. If you are using this with a @dataclass, "
            "you might have inverted the order of the decorators, the vectorstoremodel decorator should be the top one."
        )
    fields = []
    for param in parameters.values():
        field = _parse_parameter_to_field(param)
        if field:
            fields.append(field)

    return VectorStoreRecordDefinition(
        fields=fields,
        collection_name=collection_name,
    )


# region: VectorStoreModel decorator


_T = TypeVar("_T")


@release_candidate
def vectorstoremodel(
    cls: type[_T] | None = None,
    collection_name: str | None = None,
) -> type[_T]:
    """Returns the class as a vector store model.

    This decorator makes a class a vector store model.
    There are three things being checked:
    - The class must have at least one field with a annotation,
        of type VectorStoreRecordKeyField, VectorStoreRecordDataField or VectorStoreRecordVectorField.
    - The class must have exactly one field with the VectorStoreRecordKeyField annotation.
    - When creating a Vector Field, either supply the property type directly,
    or make sure to set the property that you want the index to use first.


    Args:
        cls: The class to be decorated.
        collection_name: The name of the collection to be used.
            This is used to set the collection name in the VectorStoreRecordDefinition.

    Raises:
        VectorStoreModelException: If there are no fields with a VectorStoreRecordField annotation.
        VectorStoreModelException: If there are fields with no name.
        VectorStoreModelException: If there is no key field.
    """

    def wrap(cls: type[_T]) -> type[_T]:
        # get fields and annotations
        cls_sig = signature(cls)
        setattr(cls, "__kernel_vectorstoremodel__", True)
        setattr(
            cls,
            "__kernel_vectorstoremodel_definition__",
            _parse_signature_to_definition(cls_sig.parameters, collection_name),
        )

        return cls  # type: ignore

    # See if we're being called as @vectorstoremodel or @vectorstoremodel().
    if cls is None:
        # We're called with parens.
        return wrap  # type: ignore

    # We're called as @vectorstoremodel without parens.
    return wrap(cls)
