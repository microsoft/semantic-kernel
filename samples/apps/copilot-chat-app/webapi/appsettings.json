{
  //
  // CopilotChat Application Settings
  // 
  // Quickstart: Update the "Completion" and "Embedding" sections below to use your own AI services.
  // 
  // Consider populating secrets, such as "Key" and "ConnectionString" properties, from dotnet's user-secrets when running locally.
  // https://learn.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-7.0&tabs=windows#secret-manager       
  // Values in user secrets and (optionally) Key Vault take precedence over those in this file.
  //

  // The port on which the web API will listen for requests.
  "ServicePort": "40443",

  // True to use HTTP instead of HTTPS - recommended only for development purposes.
  "UseHttp": true, 
  
  // Optional directory from which to load semantic skills (e.g., "./SemanticSkills").
  "SemanticSkillsDirectory": "",

  // Optional URI of the Key Vault for secrets (e.g., "https://contoso.vault.azure.net/").
  "KeyVaultUri": "",

  "Completion": {
    //
    // Completions are used for generating AI responses from the user's input.
    //
    // To use Azure OpenAI as the AI completion service:
    //  - Set AIService to "AzureOpenAI"
    //  - Set DeploymentOrModelId to the name of the deployment to use (e.g., "gpt-35-turbo", "gpt-4", etc.)
    //  - Set Endpoint to the endpoint of your Azure OpenAI instance (e.g., "https://contoso.openai.azure.com")
    //  - Set Key using dotnet's user secrets (see above) (i.e. dotnet user-secrets set "Completion:Key" "MY_AZURE_OPENAI_KEY")
    // 
    // To use OpenAI as the AI completion service:
    //  - Set AIService to "OpenAI"
    //  - Set DeploymentOrModelId to the name of the deployment to use (e.g., "gpt-3.5-turbo", "gpt-4", etc.)
    //  - Set Key using dotnet's user secrets (see above) (i.e. dotnet user-secrets set "Completion:Key" "MY_OPENAI")
    //
    "Label": "Completion",
    "AIService": "AzureOpenAI", 
    "DeploymentOrModelId": "gpt-35-turbo",
    "Endpoint": "" // ignored when AIService is "OpenAI"
    // "Key": ""
  },

  "Embedding": {
    //
    // Embeddings are used for semantically classifying memories.
    //
    // To use Azure OpenAI as the AI embedding service:
    //  - Set AIService" to "AzureOpenAI"
    //  - Set DeploymentOrModelId" to the name of the deployment to use (e.g., "text-embedding-ada-002")
    //  - Set Endpoint" to the endpoint of your Azure OpenAI instance (e.g., "https://contoso.openai.azure.com")
    //  - Set Key" using dotnet's user secrets (see above) (i.e. dotnet user-secrets set "Embedding:Key" "MY_AZURE_OPENAI_KEY")
    // 
    // To use OpenAI as the AI embedding service:
    //  - Set AIService to "OpenAI"
    //  - Set DeploymentOrModelId to the name of the deployment to use (e.g., "text-embedding-ada-002" )
    //  - Set Key using dotnet's user secrets (see above) (i.e. dotnet user-secrets set "Embedding:Key" "MY_OPENAI")
    //
    "Label": "Embeddings",
    "AIService": "AzureOpenAI",
    "DeploymentOrModelId": "text-embedding-ada-002",
    "Endpoint": "" // ignored when AIService is "OpenAI"
    // "Key": ""
  },

  "AzureSpeech": {
    //
    // - Set the Region to the region of your Azure Speech resource (e.g., "westus").
    // - Set the Key using dotnet's user secrets (see above) (i.e. dotnet user-secrets set "AzureSpeech:Key" "MY_AZURE_SPEECH_KEY")
    // 
    "Label": "AzureSpeech",
    "Region": ""
    // "Key":
  },

  "ChatStore": {
    //
    // Chat stores are used for storing chat sessions and messages.
    // - Supported Types are "volatile", "filesystem", or "cosmos".
    //
    "Type": "volatile", 
    "Filesystem": {
      "FilePath": "./data/chatstore.json"
    },
    "Cosmos": {
      "Database": "CopilotChat",
      "ChatSessionsContainer": "chatsessions",
      "ChatMessagesContainer": "chatmessages"
      // "ConnectionString": // dotnet user-secrets set "ChatStore:Cosmos:ConnectionString" "MY_COSMOS_CONNECTION_STRING"
    }
  },

  "MemoriesStore": {
    //
    // Memories stores are used for storing new memories and retrieving semantically similar memories.
    // - Supported Types are "volatile" or "qdrant".
    // - When using Qdrant, see ./README.md for local deployment instructions.
    //
    "Type": "volatile",
    "Qdrant": {
      "Host": "http://localhost", // Endpoint of the Qdrant server
      "Port": "6333", // Port of the Qdrant server
      "VectorSize": 1536 // Size of the vectors used by the Qdrant server
    }
  },
  
  //
  // CORS configuration
  //
  "AllowedHosts": "*",
  "AllowedOrigins": [
    "http://localhost:3000" // The frontend application
  ],

  //
  // Logging configuration
  //
  "Logging": {
    "LogLevel": {
      "Default": "Warning",
      "Microsoft.AspNetCore.Hosting": "Information",
      "Microsoft.Hosting.Lifetime": "Information",
      "Microsoft.SemanticKernel": "Information"
    }
  }
}
