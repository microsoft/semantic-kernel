{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99a80181",
   "metadata": {},
   "source": [
    "# Introduction to the Planner\n",
    "\n",
    "The Planner is one of the fundamental concepts of the Semantic Kernel.\n",
    "\n",
    "It makes use of the collection of skills that have been registered to the kernel and using AI, will formulate a plan to execute the given ask.\n",
    "\n",
    "We encourage you to implement your own versions of the planner that fit your user needs.\n",
    "\n",
    "Read more about it [here](https://aka.ms/sk/concepts/planner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install semantic-kernel==0.3.1.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e59885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion, OpenAITextCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI backend used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c885ced",
   "metadata": {},
   "source": [
    "### Setting Up the Planner\n",
    "Here we will be using a BasicPlanner that will create a sequential plan to be evaluated in order. The output of a function becomes the inputs of the next function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e90624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning.basic_planner import BasicPlanner\n",
    "planner = BasicPlanner()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5d86739",
   "metadata": {},
   "source": [
    "### Providing skills to the planner\n",
    "The planner needs to know what skills are available to it. Here we'll give it access to the `SummarizePlugin` and `WriterPlugin` we have defined on disk. This will include many semantic functions, of which the planner will intelligently choose a subset. \n",
    "\n",
    "You can also include native functions as well. Here we'll add the TextSkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"../../skills/\"\n",
    "summarize_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizePlugin\")\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"WriterPlugin\")\n",
    "text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "deff5675",
   "metadata": {},
   "source": [
    "Define your ASK. What do you want the Kernel to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d537981",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a few date ideas. She speaks French so write it in French.\n",
    "Convert the text to uppercase\"\"\"\n",
    "original_plan = await planner.create_plan_async(ask, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88411884",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_plan.generated_plan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "147587de",
   "metadata": {},
   "source": [
    "You can see that the Planner took my ask and converted it into an JSON-based plan detailing\n",
    "how the AI would go about solving this task, making use of the skills that the Kernel has available to it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1318dc72",
   "metadata": {},
   "source": [
    "As you can see in the above plan, the AI has determined which functions to call \n",
    "in order to fulfill the user ask. The output of each step of the plan becomes the `input` to the next function. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a64c88a7",
   "metadata": {},
   "source": [
    "Let's also define an inline skill and have it be available to the Planner.\n",
    "Be sure to give it a function name and skill name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the above in the style of Shakespeare.\n",
    "\"\"\"\n",
    "shakespeareFunction = kernel.create_semantic_function(sk_prompt, \"shakespeare\", \"ShakespeareSkill\",\n",
    "                                                      max_tokens=2000, temperature=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "305743f5",
   "metadata": {},
   "source": [
    "Let's update our ask using this new skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd23ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a few date ideas.\n",
    "She likes Shakespeare so write using his style. She speaks French so write it in French.\n",
    "Convert the text to uppercase.\"\"\"\n",
    "\n",
    "new_plan = await planner.create_plan_async(ask, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_plan.generated_plan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5e6ac56",
   "metadata": {},
   "source": [
    "### Executing the plan\n",
    "\n",
    "Now that we have a plan, let's try to execute it! The Planner has a function called `execute_plan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await planner.execute_plan_async(new_plan, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9727c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d2f8d04",
   "metadata": {},
   "source": [
    "# Let's see how the planner would work with a ChatCompletion model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25aa0e28",
   "metadata": {},
   "source": [
    "Planner works best with more powerful models like `gpt4`, but because that's a ChatCompletion model, we need to modify the kernel to use that instead. Let's see how it works with the cheaper `gpt-35-turbo` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06907360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_chat_service(\n",
    "        \"chat_completion\",\n",
    "        AzureChatCompletion(\"gpt-35-turbo\", endpoint, api_key),\n",
    "    )\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_chat_service(\n",
    "        \"chat-gpt\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551cabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"../../skills/\"\n",
    "summarize_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizePlugin\")\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"WriterPlugin\")\n",
    "text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183de28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "I need to plan a birthday party for my best friend. He loves racecars and only speaks Spanish.\n",
    "Translate the ideas and make the text in all capital letters.\"\"\"\n",
    "chatgpt_plan = await planner.create_plan_async(ask, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9546ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chatgpt_plan.generated_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21782c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await planner.execute_plan_async(chatgpt_plan, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
